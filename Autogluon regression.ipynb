{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d82e60-21e5-4196-a5cc-f196da209154",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this regression project, we use **AutoGluon**, a high-level AutoML framework, to predict **Temperature** based on various weather-related features. The goal is to develop a model that can estimate temperature using attributes like humidity, wind speed, UV index, cloud cover, and more.\n",
    "\n",
    "AutoGluon simplifies the modeling process by automatically handling preprocessing, feature engineering, model selection, and hyperparameter tuning, making it highly effective for rapid experimentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3273227-a578-4f9b-8adf-30a330b135c1",
   "metadata": {},
   "source": [
    "## Data Definitions\n",
    "\n",
    "Here are the feature columns used in this regression task:\n",
    "\n",
    "- `Humidity`: Humidity percentage.\n",
    "- `Wind Speed`: Wind speed in km/h.\n",
    "- `Precipitation (%)`: Percentage likelihood of precipitation.\n",
    "- `Cloud Cover`: Type of cloud presence (e.g., clear, overcast).\n",
    "- `Atmospheric Pressure`: Atmospheric pressure in hPa.\n",
    "- `UV Index`: Intensity of UV radiation.\n",
    "- `Season`: Season in which the observation was recorded.\n",
    "- `Visibility (km)`: Visibility range in kilometers.\n",
    "- `Location`: Type of location (e.g., inland, coastal, mountain).\n",
    "\n",
    "The target variable is:\n",
    "- `Temperature`: Temperature in degrees Celsius, to be predicted using the features above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a3c34-14d6-43bc-a536-55a1d434bb2b",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We use the `TabularPredictor` from AutoGluon, specifying `regression` as the problem type and `rmse` (Root Mean Squared Error) as the evaluation metric.\n",
    "\n",
    "AutoGluon automatically trained multiple models, including gradient boosting, random forests, neural networks, and k-nearest neighbors. It also evaluated and ranked them using the leaderboard function.\n",
    "\n",
    "This AutoML approach streamlines the development of regression models by managing data preparation, modeling, and evaluation in a single step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec95b616-2510-4b36-b8b8-91dbc63f7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099070f8-caae-49a2-a672-6d8610db6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Program Files\\\\python\\\\weather_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c33c3f1-e3eb-47a7-8dcf-e4f0c5372f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and classification target\n",
    "df = df.drop(columns=[\"CaseId\", \"Weather Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d1f636-c5a3-4f17-aac4-3771bc4e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression target\n",
    "target = \"Temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a03db1f-897a-4059-b6a4-e4a073b4ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b19d87a-d481-4fcd-ad51-58b61c4955e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250416_031214\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       5.91 GB / 15.85 GB (37.3%)\n",
      "Disk Space Avail:   47.90 GB / 237.93 GB (20.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"C:\\Users\\HP\\AutogluonModels\\ag-20250416_031214\"\n",
      "Train Data Rows:    10560\n",
      "Train Data Columns: 9\n",
      "Label Column:       Temperature\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6039.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['Wind Speed', 'Atmospheric Pressure', 'Visibility (km)']\n",
      "\t\t('int', [])    : 3 | ['Humidity', 'Precipitation (%)', 'UV Index']\n",
      "\t\t('object', []) : 3 | ['Cloud Cover', 'Season', 'Location']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Cloud Cover', 'Season', 'Location']\n",
      "\t\t('float', [])    : 3 | ['Wind Speed', 'Atmospheric Pressure', 'Visibility (km)']\n",
      "\t\t('int', [])      : 3 | ['Humidity', 'Precipitation (%)', 'UV Index']\n",
      "\t0.2s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.52 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 9504, Val Rows: 1056\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-14.3314\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-14.3537\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-12.0608\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-12.0118\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-11.9861\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.7s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-11.8764\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-12.0702\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.92s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-12.1964\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.17s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-11.8153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-12.0059\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'CatBoost': 0.409, 'XGBoost': 0.318, 'RandomForestMSE': 0.273}\n",
      "\t-11.7334\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 44.36s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10078.6 rows/s (1056 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\Users\\HP\\AutogluonModels\\ag-20250416_031214\")\n"
     ]
    }
   ],
   "source": [
    "# Train AutoGluon regression model\n",
    "predictor = TabularPredictor(label=target, problem_type='regression', eval_metric='rmse').fit(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b87a8e-94d1-4e21-be5d-a500a38ba0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-10.769362</td>\n",
       "      <td>-11.733382</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.566389</td>\n",
       "      <td>0.104777</td>\n",
       "      <td>21.668882</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048856</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-10.841651</td>\n",
       "      <td>-11.815297</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.759967</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.759967</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-10.847286</td>\n",
       "      <td>-12.070217</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.443971</td>\n",
       "      <td>0.080368</td>\n",
       "      <td>2.919394</td>\n",
       "      <td>0.443971</td>\n",
       "      <td>0.080368</td>\n",
       "      <td>2.919394</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-10.876443</td>\n",
       "      <td>-12.011820</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.693834</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.693834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-10.914173</td>\n",
       "      <td>-12.060823</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>1.055236</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>1.055236</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.917013</td>\n",
       "      <td>-11.876443</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.031247</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>11.158750</td>\n",
       "      <td>0.031247</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>11.158750</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-11.014016</td>\n",
       "      <td>-12.005856</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>1.087857</td>\n",
       "      <td>0.017010</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>1.087857</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-11.046298</td>\n",
       "      <td>-11.986148</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.485807</td>\n",
       "      <td>0.087788</td>\n",
       "      <td>9.701310</td>\n",
       "      <td>0.485807</td>\n",
       "      <td>0.087788</td>\n",
       "      <td>9.701310</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-11.163615</td>\n",
       "      <td>-12.196396</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.094757</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>12.170300</td>\n",
       "      <td>0.094757</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>12.170300</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-12.971853</td>\n",
       "      <td>-14.331438</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.020629</td>\n",
       "      <td>3.052582</td>\n",
       "      <td>0.040568</td>\n",
       "      <td>0.020629</td>\n",
       "      <td>3.052582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-12.995997</td>\n",
       "      <td>-14.353677</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.040561</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>0.022703</td>\n",
       "      <td>0.040561</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val              eval_metric  \\\n",
       "0   WeightedEnsemble_L2  -10.769362 -11.733382  root_mean_squared_error   \n",
       "1               XGBoost  -10.841651 -11.815297  root_mean_squared_error   \n",
       "2         ExtraTreesMSE  -10.847286 -12.070217  root_mean_squared_error   \n",
       "3              LightGBM  -10.876443 -12.011820  root_mean_squared_error   \n",
       "4            LightGBMXT  -10.914173 -12.060823  root_mean_squared_error   \n",
       "5              CatBoost  -10.917013 -11.876443  root_mean_squared_error   \n",
       "6         LightGBMLarge  -11.014016 -12.005856  root_mean_squared_error   \n",
       "7       RandomForestMSE  -11.046298 -11.986148  root_mean_squared_error   \n",
       "8       NeuralNetFastAI  -11.163615 -12.196396  root_mean_squared_error   \n",
       "9        KNeighborsUnif  -12.971853 -14.331438  root_mean_squared_error   \n",
       "10       KNeighborsDist  -12.995997 -14.353677  root_mean_squared_error   \n",
       "\n",
       "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.566389       0.104777  21.668882                 0.015838   \n",
       "1         0.033496       0.012964   0.759967                 0.033496   \n",
       "2         0.443971       0.080368   2.919394                 0.443971   \n",
       "3         0.014207       0.008019   0.693834                 0.014207   \n",
       "4         0.025460       0.010044   1.055236                 0.025460   \n",
       "5         0.031247       0.004025  11.158750                 0.031247   \n",
       "6         0.017010       0.015621   1.087857                 0.017010   \n",
       "7         0.485807       0.087788   9.701310                 0.485807   \n",
       "8         0.094757       0.023085  12.170300                 0.094757   \n",
       "9         0.040568       0.020629   3.052582                 0.040568   \n",
       "10        0.049628       0.022703   0.040561                 0.049628   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000000           0.048856            2       True   \n",
       "1                 0.012964           0.759967            1       True   \n",
       "2                 0.080368           2.919394            1       True   \n",
       "3                 0.008019           0.693834            1       True   \n",
       "4                 0.010044           1.055236            1       True   \n",
       "5                 0.004025          11.158750            1       True   \n",
       "6                 0.015621           1.087857            1       True   \n",
       "7                 0.087788           9.701310            1       True   \n",
       "8                 0.023085          12.170300            1       True   \n",
       "9                 0.020629           3.052582            1       True   \n",
       "10                0.022703           0.040561            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           9  \n",
       "2           7  \n",
       "3           4  \n",
       "4           3  \n",
       "5           6  \n",
       "6          10  \n",
       "7           5  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View model performance\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e45a3-6a09-4ebe-9052-ac0bbf446183",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "AutoGluon enabled us to efficiently build a robust regression model for predicting temperature. The best-performing model was selected based on RMSE, providing us with a reliable tool for forecasting temperatures based on other environmental conditions.\n",
    "\n",
    "With minimal manual tuning, we achieved high-quality results. This highlights the strength of AutoML in quickly delivering predictive models that are both accurate and scalable. Future improvements may involve retraining with additional features, performing model interpretability analysis, or deploying the model as an API.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
