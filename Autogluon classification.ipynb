{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bb5357-86b6-430f-93b3-aef02b125c25",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we use **AutoGluon**, a powerful AutoML framework, to build a multi-class classification model on a weather dataset. Our goal is to predict the **weather type** (e.g., Rainy, Cloudy, Sunny, Snowy) based on various atmospheric and environmental conditions such as temperature, humidity, wind speed, and more.\n",
    "\n",
    "AutoGluon simplifies the modeling process by automatically preprocessing data, tuning hyperparameters, and selecting the best model from a wide range of algorithms. This makes it an excellent tool for rapid and reliable model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c58b5-cdcb-413a-bfa8-cf206475912b",
   "metadata": {},
   "source": [
    "## Data Definitions\n",
    "\n",
    "Here is a brief explanation of the dataset columns:\n",
    "\n",
    "- `Temperature`: Temperature in degrees Celsius.\n",
    "- `Humidity`: Percentage of humidity in the air.\n",
    "- `Wind Speed`: Wind speed in kilometers per hour.\n",
    "- `Precipitation (%)`: The chance of precipitation as a percentage.\n",
    "- `Cloud Cover`: The type of cloud coverage (e.g., clear, partly cloudy, overcast).\n",
    "- `Atmospheric Pressure`: Pressure measured in hPa.\n",
    "- `UV Index`: Strength of ultraviolet radiation.\n",
    "- `Season`: Season when data was collected (e.g., Winter, Spring).\n",
    "- `Visibility (km)`: How far ahead one can see clearly.\n",
    "- `Location`: Type of geographic location (e.g., inland, coastal, mountain).\n",
    "- `Weather Type`: **Target variable** â€” classifies the weather as Rainy, Sunny, Cloudy, or Snowy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7453061-c748-4897-a626-62b341692a72",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We use `AutoGluon.TabularPredictor` with `accuracy` as the evaluation metric to build our classification model. AutoGluon automatically trained several models including LightGBM, XGBoost, Random Forest, CatBoost, KNN, and neural networks.\n",
    "\n",
    "The final model chosen was a **Weighted Ensemble**, which combines top models to optimize performance. Our model achieved a **validation accuracy of approximately 93.75%**, indicating strong predictive capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d9c780-63ed-4728-a0d9-3669fccc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2291ad04-e5a7-4958-b29f-cfb08836443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('C:\\\\Program Files\\\\python\\\\weather_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21eefe92-3810-44a5-8be4-266fab1fe1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['CaseId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0ca02e-0a15-485c-bffc-29ff6c066870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "614b8f4a-cafb-43f2-afb4-2b9e9fad1f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250416_025747\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       6.06 GB / 15.85 GB (38.2%)\n",
      "Disk Space Avail:   48.09 GB / 237.93 GB (20.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"C:\\Users\\HP\\AutogluonModels\\ag-20250416_025747\"\n",
      "Train Data Rows:    10560\n",
      "Train Data Columns: 10\n",
      "Label Column:       Weather Type\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['Rainy', 'Sunny', 'Cloudy', 'Snowy']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6186.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.51 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['Wind Speed', 'Atmospheric Pressure', 'Visibility (km)']\n",
      "\t\t('int', [])    : 4 | ['Temperature', 'Humidity', 'Precipitation (%)', 'UV Index']\n",
      "\t\t('object', []) : 3 | ['Cloud Cover', 'Season', 'Location']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Cloud Cover', 'Season', 'Location']\n",
      "\t\t('float', [])    : 3 | ['Wind Speed', 'Atmospheric Pressure', 'Visibility (km)']\n",
      "\t\t('int', [])      : 4 | ['Temperature', 'Humidity', 'Precipitation (%)', 'UV Index']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.60 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 9504, Val Rows: 1056\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.8939\t = Validation score   (accuracy)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.8911\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9328\t = Validation score   (accuracy)\n",
      "\t13.85s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.929\t = Validation score   (accuracy)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.929\t = Validation score   (accuracy)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9138\t = Validation score   (accuracy)\n",
      "\t2.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9157\t = Validation score   (accuracy)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.9205\t = Validation score   (accuracy)\n",
      "\t45.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9205\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9186\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9252\t = Validation score   (accuracy)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9242\t = Validation score   (accuracy)\n",
      "\t7.15s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.727, 'LightGBM': 0.091, 'RandomForestGini': 0.091, 'ExtraTreesGini': 0.091}\n",
      "\t0.9375\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 94.26s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3841.5 rows/s (1056 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\Users\\HP\\AutogluonModels\\ag-20250416_025747\")\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "predictor = TabularPredictor(label='Weather Type', eval_metric='accuracy').fit(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159f3dfd-8a7f-46f5-9d85-109f45033b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.915909</td>\n",
       "      <td>0.932765</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.118682</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>13.850857</td>\n",
       "      <td>0.118682</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>13.850857</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.915909</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.686166</td>\n",
       "      <td>0.274891</td>\n",
       "      <td>21.204796</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.190673</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.915530</td>\n",
       "      <td>0.928977</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.153589</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>3.940462</td>\n",
       "      <td>0.153589</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>3.940462</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.914015</td>\n",
       "      <td>0.928977</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.300197</td>\n",
       "      <td>0.141629</td>\n",
       "      <td>6.318104</td>\n",
       "      <td>0.300197</td>\n",
       "      <td>0.141629</td>\n",
       "      <td>6.318104</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.913636</td>\n",
       "      <td>0.915720</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.097736</td>\n",
       "      <td>2.430492</td>\n",
       "      <td>0.164557</td>\n",
       "      <td>0.097736</td>\n",
       "      <td>2.430492</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.911364</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>0.133645</td>\n",
       "      <td>7.149880</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>0.133645</td>\n",
       "      <td>7.149880</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.910985</td>\n",
       "      <td>0.913826</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.193486</td>\n",
       "      <td>0.085770</td>\n",
       "      <td>2.007129</td>\n",
       "      <td>0.193486</td>\n",
       "      <td>0.085770</td>\n",
       "      <td>2.007129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.910606</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>45.802598</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>45.802598</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.910227</td>\n",
       "      <td>0.918561</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.218417</td>\n",
       "      <td>0.070396</td>\n",
       "      <td>1.549639</td>\n",
       "      <td>0.218417</td>\n",
       "      <td>0.070396</td>\n",
       "      <td>1.549639</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.909470</td>\n",
       "      <td>0.925189</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.183510</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>3.691319</td>\n",
       "      <td>0.183510</td>\n",
       "      <td>0.030917</td>\n",
       "      <td>3.691319</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.907576</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.210436</td>\n",
       "      <td>0.087070</td>\n",
       "      <td>1.215676</td>\n",
       "      <td>0.210436</td>\n",
       "      <td>0.087070</td>\n",
       "      <td>1.215676</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.073802</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>2.958129</td>\n",
       "      <td>0.073802</td>\n",
       "      <td>0.025373</td>\n",
       "      <td>2.958129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.891098</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.079786</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.079786</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0       NeuralNetFastAI    0.915909   0.932765    accuracy        0.118682   \n",
       "1   WeightedEnsemble_L2    0.915909   0.937500    accuracy        0.686166   \n",
       "2              LightGBM    0.915530   0.928977    accuracy        0.153589   \n",
       "3            LightGBMXT    0.914015   0.928977    accuracy        0.300197   \n",
       "4      RandomForestEntr    0.913636   0.915720    accuracy        0.164557   \n",
       "5         LightGBMLarge    0.911364   0.924242    accuracy        0.572469   \n",
       "6      RandomForestGini    0.910985   0.913826    accuracy        0.193486   \n",
       "7              CatBoost    0.910606   0.920455    accuracy        0.021941   \n",
       "8        ExtraTreesEntr    0.910227   0.918561    accuracy        0.218417   \n",
       "9               XGBoost    0.909470   0.925189    accuracy        0.183510   \n",
       "10       ExtraTreesGini    0.907576   0.920455    accuracy        0.210436   \n",
       "11       KNeighborsUnif    0.884848   0.893939    accuracy        0.073802   \n",
       "12       KNeighborsDist    0.880682   0.891098    accuracy        0.079786   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.046874  13.850857                 0.118682                0.046874   \n",
       "1        0.274891  21.204796                 0.009973                0.005309   \n",
       "2        0.049867   3.940462                 0.153589                0.049867   \n",
       "3        0.141629   6.318104                 0.300197                0.141629   \n",
       "4        0.097736   2.430492                 0.164557                0.097736   \n",
       "5        0.133645   7.149880                 0.572469                0.133645   \n",
       "6        0.085770   2.007129                 0.193486                0.085770   \n",
       "7        0.005996  45.802598                 0.021941                0.005996   \n",
       "8        0.070396   1.549639                 0.218417                0.070396   \n",
       "9        0.030917   3.691319                 0.183510                0.030917   \n",
       "10       0.087070   1.215676                 0.210436                0.087070   \n",
       "11       0.025373   2.958129                 0.073802                0.025373   \n",
       "12       0.028324   0.034906                 0.079786                0.028324   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           13.850857            1       True          3  \n",
       "1            0.190673            2       True         13  \n",
       "2            3.940462            1       True          5  \n",
       "3            6.318104            1       True          4  \n",
       "4            2.430492            1       True          7  \n",
       "5            7.149880            1       True         12  \n",
       "6            2.007129            1       True          6  \n",
       "7           45.802598            1       True          8  \n",
       "8            1.549639            1       True         10  \n",
       "9            3.691319            1       True         11  \n",
       "10           1.215676            1       True          9  \n",
       "11           2.958129            1       True          1  \n",
       "12           0.034906            1       True          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a063886-6e5e-48ab-a5c8-9ea5de498ec3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Using AutoGluon, we quickly developed a high-performing classification model to predict weather types from environmental data. The ensemble model outperformed individual models and achieved over 93% accuracy. This demonstrates the power of AutoML for real-world datasets â€” enabling fast, accurate, and scalable model building with minimal manual intervention.\n",
    "\n",
    "Future work could include feature importance analysis, deploying the model, or retraining with more diverse data to improve generalizability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
